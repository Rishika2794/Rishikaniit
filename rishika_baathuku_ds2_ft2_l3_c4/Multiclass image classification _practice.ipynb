{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8581af69",
   "metadata": {},
   "source": [
    "# Image classification Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14db23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97624b40",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cedaba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bd270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as a datframe\n",
    "df = pd.DataFrame(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec369792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6    7    8    9  ...   55   56   57  \\\n",
       "0  0.0  0.0   5.0  13.0   9.0   1.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0   0.0   4.0  15.0  12.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0   7.0  15.0  13.0   1.0   0.0  0.0  0.0  8.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0   0.0   1.0  11.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5  0.0  0.0  12.0  10.0   0.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6  0.0  0.0   0.0  12.0  13.0   0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "7  0.0  0.0   7.0   8.0  13.0  16.0  15.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "8  0.0  0.0   9.0  14.0   8.0   1.0   0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9  0.0  0.0  11.0  12.0   0.0   0.0   0.0  0.0  0.0  2.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "     58    59    60    61   62   63  target  \n",
       "0   6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1   0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2   0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3   7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4   0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "5   9.0  16.0  16.0  10.0  0.0  0.0       5  \n",
       "6   1.0   9.0  15.0  11.0  3.0  0.0       6  \n",
       "7  13.0   5.0   0.0   0.0  0.0  0.0       7  \n",
       "8  11.0  16.0  15.0  11.0  1.0  0.0       8  \n",
       "9   9.0  12.0  13.0   3.0  0.0  0.0       9  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add target variable\n",
    "df['target'] = data.target\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb166f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 65)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b28663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14361cee880>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view data as image\n",
    "plt.imshow(data.images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb7e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the images b/w 0-9\n",
    "# create train and test data sets\n",
    "# build the model\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06be089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923fdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "im=data.images[0]\n",
    "im=im.astype('uint8')\n",
    "im=Image.fromarray(im).resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d2a57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genarate data folder wise\n",
    "for x in range(len(data.images)):\n",
    "    im=data.images[x]\n",
    "    im=im.astype('uint8')\n",
    "    im=Image.fromarray(im).resize((256,256))\n",
    "    for n in range(0,10):\n",
    "        if str(df.target[x])==str(n):\n",
    "            plt.imsave(f\"D:\\\\numbers\\\\train\\{n}\\\\\"+str(df.target[x])+str(x)+'.jpg',im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "396f6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 53\n",
      "127 55\n",
      "124 53\n",
      "128 55\n",
      "127 54\n",
      "127 55\n",
      "127 54\n",
      "125 54\n",
      "122 52\n",
      "126 54\n"
     ]
    }
   ],
   "source": [
    "# Split the data 20% to validation\n",
    "import os\n",
    "for y in range(0,10):\n",
    "    datafiles = f'D:\\\\numbers\\\\train\\{y}'\n",
    "    move = os.listdir(datafiles)[:round((len(os.listdir(datafiles))*30)/100)]\n",
    "    for f in move:\n",
    "        os.rename(f'D:\\\\numbers\\\\train\\{y}\\\\' + f, f'D:\\\\numbers\\\\validation\\{y}\\\\' + f)\n",
    "    print(len(os.listdir(datafiles)), len(os.listdir(f'D:\\\\numbers\\\\validation\\{y}\\\\')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a9523",
   "metadata": {},
   "source": [
    "<!-- # # Delete data & validation \n",
    "# import os\n",
    "# for y in range(0,10):\n",
    "#     datafiles = f'D:\\\\numbers\\\\train\\{y}'\n",
    "#     validation = f'D:\\\\numbers\\\\validation\\{y}'\n",
    "    \n",
    "#     print(len(os.listdir(datafiles)), len(os.listdir(validation)), \" will be deleted\")\n",
    "    \n",
    "#     for f in os.listdir(datafiles):\n",
    "#         os.remove(os.path.join(datafiles, f))\n",
    "        \n",
    "#     for f in os.listdir(validation):\n",
    "#         os.remove(os.path.join(validation, f)) -->\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e0e1d",
   "metadata": {},
   "source": [
    "# Image classification Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26bd8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam  #controls lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48765b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87d300f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image prediction\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c3caaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb783",
   "metadata": {},
   "source": [
    "# network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f27fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise the bit depth\n",
    "# for color imgs it is 3 for monochrome it is 1\n",
    "bitdepth = 3\n",
    "size = 64 #same for both height and width\n",
    "#incase if diff sizes are req create width nd height with diff values\n",
    "actualclasses = [0,1,2,3,4,5,6,7,8,9]\n",
    "outputnodes = len(actualclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fac09542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise the model\n",
    "classifier = Sequential()\n",
    "\n",
    "# convolution layer\n",
    "classifier.add(Convolution2D(64,kernel_size=(2,2),input_shape=(size,size,bitdepth),activation='relu')) #c1\n",
    "classifier.add(Convolution2D(32,kernel_size=(2,2),activation='relu')) #c2\n",
    "\n",
    "# max pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# #layer set 2\n",
    "classifier.add(Convolution2D(32,kernel_size=(3,3),activation='relu')) #c2\n",
    "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "# #layer set 3\n",
    "# classifier.add(Convolution2D(32,kernel_size=(3,3),activation='relu')) #c3\n",
    "# classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "# flatten layer\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# fully connected layer\n",
    "classifier.add(Dense(units=20,activation='relu')) #HL1\n",
    "#classifier.add(Dropout(rate=0.1)) #dropout layer1\n",
    "\n",
    "classifier.add(Dense(units=20,activation='relu')) #HL2\n",
    "#classifier.add(Dropout(rate=0.1)) #dropout layer2\n",
    "\n",
    "classifier.add(Dense(units=20,activation='relu')) #HL3\n",
    "#classifier.add(Dropout(rate=0.1)) #dropout layer3\n",
    "\n",
    "classifier.add(Dense(units=outputnodes,activation='softmax')) #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e552cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "classifier.compile(optimizer=Adam(learning_rate=0.005),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb31b42",
   "metadata": {},
   "source": [
    "# Image processing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ec03400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply image augmentation on train data\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,channel_shift_range=0.5,width_shift_range=0.5, \n",
    "                                  height_shift_range=0.5, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dd612ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply image augmentation on validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1/255,channel_shift_range=0.5,width_shift_range=0.5, \n",
    "                                  height_shift_range=0.5, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c00eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the training and validation directories to read the image files\n",
    "train_dir =r\"D:\\numbers\\train\"\n",
    "val_dir=r\"D:\\numbers\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cfdd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=1\n",
    "colormode='rgb'   #default is rgb\n",
    "targetsize=(size,size)\n",
    "classmode ='categorical' #default value is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b049d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1258 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# read the files(train)\n",
    "train_set = train_datagen.flow_from_directory(train_dir,target_size=targetsize,\n",
    "                                    class_mode=classmode,batch_size=batchsize,color_mode=colormode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "583400a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 539 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# read the files(validation)\n",
    "val_set = val_datagen.flow_from_directory(val_dir,target_size=targetsize,\n",
    "                                    class_mode=classmode,batch_size=batchsize,color_mode=colormode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddc9d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count = 1258, Validation count = 539\n"
     ]
    }
   ],
   "source": [
    "# store the train and validation counts\n",
    "train_count = train_set.n\n",
    "val_count = val_set.n\n",
    "print('Train count = {}, Validation count = {}'.format(train_count,val_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7258b",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e377266",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8d2845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1258/1258 [==============================] - 9s 7ms/step - loss: 2.3091 - accuracy: 0.0882 - val_loss: 2.3026 - val_accuracy: 0.1020\n",
      "Epoch 2/10\n",
      "1258/1258 [==============================] - 9s 7ms/step - loss: 2.3081 - accuracy: 0.0906 - val_loss: 2.3037 - val_accuracy: 0.1020\n",
      "Epoch 3/10\n",
      "1258/1258 [==============================] - 9s 7ms/step - loss: 2.3075 - accuracy: 0.1017 - val_loss: 2.3031 - val_accuracy: 0.1020\n",
      "Epoch 4/10\n",
      "1258/1258 [==============================] - 10s 8ms/step - loss: 2.3085 - accuracy: 0.0962 - val_loss: 2.3028 - val_accuracy: 0.1020\n",
      "Epoch 5/10\n",
      "1258/1258 [==============================] - 11s 9ms/step - loss: 2.3072 - accuracy: 0.0882 - val_loss: 2.3032 - val_accuracy: 0.1020\n",
      "Epoch 6/10\n",
      "1258/1258 [==============================] - 10s 8ms/step - loss: 2.3079 - accuracy: 0.0882 - val_loss: 2.3036 - val_accuracy: 0.1002\n",
      "Epoch 7/10\n",
      "1258/1258 [==============================] - 10s 8ms/step - loss: 2.3087 - accuracy: 0.0946 - val_loss: 2.3031 - val_accuracy: 0.1020\n",
      "Epoch 8/10\n",
      "1258/1258 [==============================] - 10s 8ms/step - loss: 2.3079 - accuracy: 0.0930 - val_loss: 2.3036 - val_accuracy: 0.0983\n",
      "Epoch 9/10\n",
      "1258/1258 [==============================] - 10s 8ms/step - loss: 2.3084 - accuracy: 0.0874 - val_loss: 2.3033 - val_accuracy: 0.1002\n",
      "Epoch 10/10\n",
      "1258/1258 [==============================] - 9s 8ms/step - loss: 2.3083 - accuracy: 0.0866 - val_loss: 2.3034 - val_accuracy: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1436c3cb880>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_set,steps_per_epoch=train_count,epochs=epoch,\n",
    "              validation_data = val_set,validation_steps = val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b7b16f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the test path\n",
    "test_path=r\"D:\\numbers\\test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ebbc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list is to store the filenames of the test data\n",
    "test_images=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26b70287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _,_,files in os.walk(test_path):\n",
    "    for f in files:\n",
    "        test_images.append(test_path + f)\n",
    "#print(test_images)\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc8734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the images in numpy array format\n",
    "image_stack= None\n",
    "for i in test_images:\n",
    "    img=image.load_img(i,target_size=(size,size),color_mode=colormode)\n",
    "    \n",
    "    #converting the individual image into array\n",
    "    y=image.img_to_array(img)\n",
    "    y=np.expand_dims(y,axis=0)\n",
    "    \n",
    "    #convert the image as in scale data\n",
    "    y/=255\n",
    "    \n",
    "    #stack every transformed image\n",
    "    if image_stack is None:\n",
    "        image_stack=y\n",
    "    else:\n",
    "        image_stack=np.vstack([image_stack,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce47855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c43de753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(classifier.predict(image_stack),-1)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
